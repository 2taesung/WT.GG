{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "xERfE_j7DSG1"
   },
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'tensorflow'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_1908/188831171.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mkeras\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpreprocessing\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msequence\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mpad_sequences\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mkeras\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmodels\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mSequential\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mkeras\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlayers\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mDense\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mLSTM\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mEmbedding\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mkeras\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcallbacks\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mEarlyStopping\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mModelCheckpoint\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mkeras\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpreprocessing\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtext\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mTokenizer\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'tensorflow'"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, LSTM, Embedding\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 618
    },
    "colab_type": "code",
    "id": "sdKfEq0qBuxD",
    "outputId": "4edef09c-84db-4136-f645-143c95bb56d5"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting konlpy\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/85/0e/f385566fec837c0b83f216b2da65db9997b35dd675e107752005b7d392b1/konlpy-0.5.2-py2.py3-none-any.whl (19.4MB)\n",
      "\u001b[K     |████████████████████████████████| 19.4MB 1.2MB/s \n",
      "\u001b[?25hCollecting colorama\n",
      "  Downloading https://files.pythonhosted.org/packages/c9/dc/45cdef1b4d119eb96316b3117e6d5708a08029992b2fee2c143c7a0a5cc5/colorama-0.4.3-py2.py3-none-any.whl\n",
      "Collecting JPype1>=0.7.0\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/8b/f7/a368401e630f0e390dd0e62c39fb928e5b23741b53c2360ee7d376660927/JPype1-1.0.2-cp36-cp36m-manylinux2010_x86_64.whl (3.8MB)\n",
      "\u001b[K     |████████████████████████████████| 3.8MB 48.8MB/s \n",
      "\u001b[?25hRequirement already satisfied: numpy>=1.6 in /usr/local/lib/python3.6/dist-packages (from konlpy) (1.18.5)\n",
      "Collecting beautifulsoup4==4.6.0\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/9e/d4/10f46e5cfac773e22707237bfcd51bbffeaf0a576b0a847ec7ab15bd7ace/beautifulsoup4-4.6.0-py3-none-any.whl (86kB)\n",
      "\u001b[K     |████████████████████████████████| 92kB 12.6MB/s \n",
      "\u001b[?25hRequirement already satisfied: lxml>=4.1.0 in /usr/local/lib/python3.6/dist-packages (from konlpy) (4.2.6)\n",
      "Collecting tweepy>=3.7.0\n",
      "  Downloading https://files.pythonhosted.org/packages/bb/7c/99d51f80f3b77b107ebae2634108717362c059a41384a1810d13e2429a81/tweepy-3.9.0-py2.py3-none-any.whl\n",
      "Requirement already satisfied: typing-extensions; python_version < \"3.8\" in /usr/local/lib/python3.6/dist-packages (from JPype1>=0.7.0->konlpy) (3.7.4.3)\n",
      "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.6/dist-packages (from tweepy>=3.7.0->konlpy) (1.3.0)\n",
      "Requirement already satisfied: six>=1.10.0 in /usr/local/lib/python3.6/dist-packages (from tweepy>=3.7.0->konlpy) (1.15.0)\n",
      "Requirement already satisfied: requests[socks]>=2.11.1 in /usr/local/lib/python3.6/dist-packages (from tweepy>=3.7.0->konlpy) (2.23.0)\n",
      "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.6/dist-packages (from requests-oauthlib>=0.7.0->tweepy>=3.7.0->konlpy) (3.1.0)\n",
      "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests[socks]>=2.11.1->tweepy>=3.7.0->konlpy) (2.10)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests[socks]>=2.11.1->tweepy>=3.7.0->konlpy) (2020.6.20)\n",
      "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests[socks]>=2.11.1->tweepy>=3.7.0->konlpy) (1.24.3)\n",
      "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests[socks]>=2.11.1->tweepy>=3.7.0->konlpy) (3.0.4)\n",
      "Requirement already satisfied: PySocks!=1.5.7,>=1.5.6; extra == \"socks\" in /usr/local/lib/python3.6/dist-packages (from requests[socks]>=2.11.1->tweepy>=3.7.0->konlpy) (1.7.1)\n",
      "Installing collected packages: colorama, JPype1, beautifulsoup4, tweepy, konlpy\n",
      "  Found existing installation: beautifulsoup4 4.6.3\n",
      "    Uninstalling beautifulsoup4-4.6.3:\n",
      "      Successfully uninstalled beautifulsoup4-4.6.3\n",
      "  Found existing installation: tweepy 3.6.0\n",
      "    Uninstalling tweepy-3.6.0:\n",
      "      Successfully uninstalled tweepy-3.6.0\n",
      "Successfully installed JPype1-1.0.2 beautifulsoup4-4.6.0 colorama-0.4.3 konlpy-0.5.2 tweepy-3.9.0\n"
     ]
    }
   ],
   "source": [
    "!pip install konlpy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 334
    },
    "colab_type": "code",
    "id": "IIWqqSACBRO1",
    "outputId": "2b7277e8-eacb-475c-c64f-05a1f73af0d5"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "            id                                           document  label\n",
      "0      6270596                                                굳 ㅋ      1\n",
      "1      9274899                               GDNTOPCLASSINTHECLUB      0\n",
      "2      8544678             뭐야 이 평점들은.... 나쁘진 않지만 10점 짜리는 더더욱 아니잖아      0\n",
      "3      6825595                   지루하지는 않은데 완전 막장임... 돈주고 보기에는....      0\n",
      "4      6723715  3D만 아니었어도 별 다섯 개 줬을텐데.. 왜 3D로 나와서 제 심기를 불편하게 하죠??      0\n",
      "...        ...                                                ...    ...\n",
      "49995  4608761          오랜만에 평점 로긴했네ㅋㅋ 킹왕짱 쌈뽕한 영화를 만났습니다 강렬하게 육쾌함      1\n",
      "49996  5308387       의지 박약들이나 하는거다 탈영은 일단 주인공 김대희 닮았고 이등병 찐따 OOOO      0\n",
      "49997  9072549                 그림도 좋고 완성도도 높았지만... 보는 내내 불안하게 만든다      0\n",
      "49998  5802125     절대 봐서는 안 될 영화.. 재미도 없고 기분만 잡치고.. 한 세트장에서 다 해먹네      0\n",
      "49999  6070594                                         마무리는 또 왜이래      0\n",
      "\n",
      "[50000 rows x 3 columns]\n",
      "# preproecssing done\n",
      "# split done\n",
      "# tokenization done\n",
      "# int_encoding done\n"
     ]
    }
   ],
   "source": [
    "########## 한글 전처리부분입니다 ########\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from konlpy.tag import Okt\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "naver_data = pd.read_table(\"ratings_test.txt\", encoding='utf-8')\n",
    "# 단어 아니면 삭제\n",
    "print(naver_data)\n",
    "naver_data['document'] = naver_data['document'].str.replace(\"[^\\w]\", \" \")\n",
    "# 혹시 공백이 있으면 null array로\n",
    "naver_data['document'] = naver_data['document'].replace('', np.nan)\n",
    "naver_data['label'] = naver_data['label'].replace('', np.nan)\n",
    "# null array 모두 제거 (공백인 열 모두 제거)\n",
    "naver_data = naver_data.dropna(how='any')\n",
    "\n",
    "print(\"# preproecssing done\")\n",
    "\n",
    "# test/train 스플릿하고\n",
    "review_train, review_test, y_train, y_test = train_test_split(naver_data['document'], naver_data['label'], test_size=0.05, shuffle=False, random_state=1004)\n",
    "\n",
    "print('# split done')\n",
    "\n",
    "# stopwords 지정\n",
    "stopwords = ['를', '을', '이', '가', '으로', '로', '에', '에서']\n",
    "\n",
    "# 토큰화 진행\n",
    "X_train = []\n",
    "for stc in review_train:\n",
    "    token = []\n",
    "    words = Okt().morphs(stc, stem=True)\n",
    "    for word in words:\n",
    "        if word not in stopwords:\n",
    "            token.append(word)\n",
    "    X_train.append(token)\n",
    "\n",
    "X_test = []\n",
    "for stc in review_test:\n",
    "    token = []\n",
    "    words = Okt().morphs(stc, stem=True)\n",
    "    for word in words:\n",
    "        if word not in stopwords:\n",
    "            token.append(word)\n",
    "    X_test.append(token)\n",
    "\n",
    "print('# tokenization done')\n",
    "\n",
    "# X_train 단어들을 토대로 정수 인덱스 설정, 전체 단어 갯수 설정\n",
    "# 유의미한 단어? 빈도수가 1~2개인 단어 버려도 큰 영향을 끼치지 않을것 -> count함수써서 빈도수 낮은 것들을 버리고, 남은 단어의 갯수들\n",
    "tokenizer = Tokenizer(20000)\n",
    "tokenizer.fit_on_texts(X_train)\n",
    "\n",
    "# 설정된 정수 인덱스를 토대로 변환\n",
    "X_train = tokenizer.texts_to_sequences(X_train)\n",
    "X_test = tokenizer.texts_to_sequences(X_test)\n",
    "\n",
    "print('# int_encoding done')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "XcDIYJSvBkBt"
   },
   "outputs": [],
   "source": [
    "# 문장 길이를 맞춰준다\n",
    "# 임의로 맞추는게 아니고, 데이터셋을 보면서 최대 문장의 길이가 얼마인지 확인하시고 거기에 맞춰서\n",
    "# imdb일때는 500, 네이버일때는 50으로 맞췄었습니다!\n",
    "max_len = 50\n",
    "X_train = pad_sequences(X_train, maxlen=max_len)\n",
    "X_test = pad_sequences(X_test, maxlen=max_len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Ni66SdmKBmei"
   },
   "outputs": [],
   "source": [
    "# 레이어들을 쌓을 모델을 생성\n",
    "model = Sequential()\n",
    "# 단어를 임베딩하는데, 5000개 (imdb) 혹은 20000개 (네이버) 의 단어를 120차원으로 내보내겠다\n",
    "# 1인자 = 내가 넣을 단어의 갯수 (총 인덱스의 갯수), 2인자 = 출력할 차원 (덴스 벡터의 차원), 3인자 = 문장의 길이\n",
    "model.add(Embedding(20000, 120))\n",
    "# RNN - simpleRNN / LSTM\n",
    "model.add(LSTM(120))\n",
    "# 긍정/부정을 판단하니까 이진 분류 -> sigmoid 함수 사용\n",
    "model.add(Dense(1, activation='sigmoid'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "-c2kdH2GBomF"
   },
   "outputs": [],
   "source": [
    "# 혹시 5회 이상 검증데이터 loss가 증가하면, 과적합될 수 있으므로 학습을 조기종료!\n",
    "early_stop = EarlyStopping(monitor='val_loss', mode='min', verbose=1, patience=5)\n",
    "# 훈련을 거듭하면서, 가장 검증데이터 정확도가 높았던 순간을 체크포인트로 저장\n",
    "model_check = ModelCheckpoint('the_best.h5', monitor='val_acc', mode='max', verbose=1, save_best_only=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 87
    },
    "colab_type": "code",
    "id": "vt9quqBTBp2C",
    "outputId": "e8a63c49-c31c-4504-e246-757cdc8f6416"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "742/743 [============================>.] - ETA: 0s - loss: 0.4185 - acc: 0.8061\n",
      "Epoch 00001: val_acc improved from -inf to 0.82560, saving model to the_best.h5\n",
      "743/743 [==============================] - 22s 29ms/step - loss: 0.4185 - acc: 0.8061 - val_loss: 0.3891 - val_acc: 0.8256\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7f1e5d9ec748>"
      ]
     },
     "execution_count": 8,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 긍정/부정을 판단하니까 손실함수는 이진 교차 엔트로피, 최적화는 adam, 평가 기준은 acc (출력할때 뜬다)\n",
    "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['acc'])\n",
    "model.fit(X_train, y_train, validation_data=(X_test, y_test), epochs=1, batch_size=64, callbacks=[early_stop, model_check])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 52
    },
    "colab_type": "code",
    "id": "7RQNEpP_FaGc",
    "outputId": "82d10e2e-98d3-43fd-80d6-ade4a7474272"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "79/79 [==============================] - 0s 4ms/step - loss: 0.3891 - acc: 0.8256\n",
      "[0.38906165957450867, 0.8256000280380249]\n"
     ]
    }
   ],
   "source": [
    "# 정확도 측정\n",
    "# 출력하면 [loss, acc]\n",
    "print(model.evaluate(X_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "lG46AkWUbJTT"
   },
   "outputs": [],
   "source": [
    "model.save('webtoon_contents_model.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 239
    },
    "colab_type": "code",
    "id": "26o0O30YulFR",
    "outputId": "eaf900ea-0a53-43c5-a867-61f83544311e"
   },
   "outputs": [
    {
     "ename": "Error",
     "evalue": "ignored",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mError\u001b[0m                                     Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-12-6290cabf849e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcsv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0ma\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 15\u001b[0;31m \u001b[0;32mfor\u001b[0m \u001b[0mrr\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mdata\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     16\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mError\u001b[0m: line contains NULL byte"
     ]
    }
   ],
   "source": [
    "import re\n",
    "# data['content'] = data['content'].str.replace(\"[^\\w]\", \" \")\n",
    "# # 혹시 공백이 있으면 null array로\n",
    "# data['content'] = data['content'].replace('', np.nan)\n",
    "# # null array 모두 제거 (공백인 열 모두 제거)\n",
    "# data = data.dropna(how='any')\n",
    "# test_data= ['계속 스토리 전개 안하고 과거 회상만 한다고 하는데. 그럼 대체 무슨 스토리 진행을 바라는거임? 목포에 도착하면 스토리는 거의 막바지일텐데 가는 동안 택시 안에서 보여줄 수 있는 스토리는 둘의 대화 말고는 없음.. 그리고 소설 ‘운수 좋은 날’ 에서 결말은 인력거꾼인 주인공이 그날 따라 수입이 좋고 운이 좋은 일이 많이 생겨 아픈 아내를 위해 설렁탕을 사갔으나 결국 아내는 죽어있더라 라는 결말임. 이미 저 택시 아저씨 가족의 죽음을 예상한 댓글들은 종종 보였고, 저 살인마가 가장 처음 저지른 살인부터 시간 순서대로 죽인 사람들을 회상과 대화를 통해 보여주고 마지막으로 기사에게 말해줄 내용은 택시 아저씨 가족을 죽인 이야기를 들려줄 것 같음.. 이 작품은 애초에 택시 안에서 목포까지 가는 과정을 보여주는 작품이고 그러면 대화와 회상이 작품의 주를 이루는게 당연한건데 대체 뭐가 불만들인지 잘 모르겠음',\n",
    "#             '저정도 머리라면 지금 순간도 다 살인마의 계획일 수도 있겠군요. 이전부터 트렁크에 실려 있는 시신이 아내고 잘라온 손가락도 아내일거라는 추측이 있었는데, 이번 화로 그 추측이 맞다는 확신이 듭니다. 택시기사 또한 이전의 사람들처럼 철저하게 조사된 사람이고, 아내를 먼저 죽인 뒤 그가 택시를 통해 아내의 시신을 유기하는 것을 도왔다는 그림을 설계해서 모든 걸 알게 된 후의 택시기사의 반응을 기대하는 모습이 아닐까 생각이 드네요. 정신적 살해의 쾌감을 느낀 뒤라는 설정이 나온 만큼 이런 생각도 듭니다.',\n",
    "#             '행님. 과거편이니 만큼 세세한 사건의 장황한 묘사보다 하나 하나 시원하게 떡밥 풀어가면서 휙휙 지나갔으면 하는데 그게 안되니까 원성을 사는겁니다. 덕형은 누구고, 피바다는 어떻게 죽었고, 광님이 곁에 슈빌은 우째 변했고, 구상룡 와꾸나 함 보고싶고, 이게 중헌거지 계속 그런건 안보여주고 새로운 인물 설정 스토리가 추가되니 지루하고 싸움에 관심이 없어지는 겁니다. 결국 우리가 궁금한건 저승세계고 그게 과거랑 어째 연결되는지 궁금한겁니다. 전개 다이어트좀 필요해보입니다.',\n",
    "#             '아니 ㅋㅋㅋㅋ 유명한 연예인 집에 맨날 편지 썼다고 연예인이 바로 밥먹으러 집에 들어오라고 말하냐 그것도 2주만에 ㅋㅋ 말이 너무 안됨,,']\n",
    "import csv\n",
    "r=open('1스토리74전.csv', encoding='utf-8')\n",
    "data=csv.reader(r)\n",
    "a = []\n",
    "for rr in data :\n",
    "  \n",
    "\n",
    "  test_data = rr\n",
    "  test_data = [re.sub(\"[^\\w]\", \" \",x) for x in test_data]\n",
    "  # stopwords 지정\n",
    "  stopwords = ['를', '을', '이', '가', '으로', '로', '에', '에서']\n",
    "  x_test=[]\n",
    "  stc_len = []\n",
    "  for stc in test_data:\n",
    "      \n",
    "    token = []\n",
    "    words = Okt().morphs(stc, stem=True)\n",
    "    \n",
    "    for word in words:\n",
    "      if word not in stopwords:\n",
    "          token.append(word)\n",
    "    x_test.append(token)\n",
    "\n",
    "\n",
    "  # 설정된 정수 인덱스를 토대로 변환\n",
    "  x_test = tokenizer.texts_to_sequences(x_test)\n",
    "\n",
    "  max_len = 50\n",
    "  x_test = pad_sequences(x_test, maxlen=max_len)\n",
    "  a.append(x_test)\n",
    "\n",
    "# print(a[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 72
    },
    "colab_type": "code",
    "id": "ddDHXl7pBriS",
    "outputId": "556ce9c1-089d-459b-8734-82195d5597d1"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.40619838, 0.409797, 0.41492286, 0.28784797, 0.31623304, 0.43101987, 0.49925303, 0.38592392, 0.41077664, 0.3377552, 0.4475031, 0.3313947, 0.46537098, 0.28870207, 0.3831992, 0.36070094, 0.4163593, 0.46140075, 0.33674204, 0.33526447, 0.36174327, 0.4324261, 0.42570847, 0.38322014, 0.42187434, 0.3935379, 0.48077136, 0.38047287, 0.48134923, 0.38897505, 0.46627152, 0.33963084, 0.44762257, 0.44848326, 0.46516943, 0.41340518, 0.48467723, 0.48713002, 0.50029725, 0.3811201, 0.37717932, 0.49644864, 0.40094468, 0.3850133, 0.4555124, 0.5348732, 0.39781675, 0.4030965, 0.393495, 0.4430431, 0.5114241, 0.54981124, 0.3844889, 0.4216792, 0.33020014, 0.41621044, 0.4107599, 0.47808638, 0.6330894, 0.44926196, 0.37399617, 0.5047824, 0.41720122, 0.354586, 0.42197305, 0.46271417, 0.39303, 0.36520746, 0.42120287, 0.34081152, 0.41944954, 0.45614308, 0.390689]\n",
      "<class 'list'>\n"
     ]
    }
   ],
   "source": [
    "# X 값은 전처리, 토큰화, 정수인코딩이 된 상태의 문장이어야\n",
    "b = []\n",
    "\n",
    "for i in a:\n",
    "  predic=model.predict(i)\n",
    "  # print(sum(predic)/100)\n",
    "  b.append(predic.mean())\n",
    "  \n",
    "\n",
    "print(b)\n",
    "print(type(b))\n",
    " \n",
    "# for idx,len in enumerate(stc_len):\n",
    "#   pre_sc = predic[idx]\n",
    "#   print(pre[-len:])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "RE7w8qOYMXlb"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "팀플연습.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
